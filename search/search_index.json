{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is useless_isam ? I was working on a C++ implementation of db_tutorial made by cstack as a pet project for my portfolio when I started to get hardy time on the B+Tree implementation section. After learning about B-Tree and B+Tree, I was still struggling with indexing and persistence on files. So I decided to switch to something easier and casually bumped into ISAM indexing. Why useless? Because with this project you can't insert new records. So it's a read only database. Just basic search queries and nothing else. Also, record columns are hard-coded within the source code. So neither CREAT TABLE statement type for column definition. Quite useless, don't you agree? Well, maybe not so much useless... I like writing code and I am a C++ lover, so this small and simple project is ideal to put some things I learned until now in practice. Goal, I hope, is to produce a clean and well-written code and not something like if it compile and works then it's fine, no matter how it is made . Some keywords covered by this project are database isam indexing parsing lexer paging file manipulation paging caching cmake tokens record exception handling and I hope there will be more in the future. Overvew ISAM is used to fast retrieve data from a database. So I decided to use a binary file for storing the dataset because it allows random access to records. Also, we need a dataset to populate our database. And don't forget that the database must be sorted in order to create an index file and support range selections. Let's put in order... generate a database binary file from a dataset sort the database binary file by a column generate the index binary file So I decided to archieve these points with three separate executables. csv2bin The program will use a textual dataset to build a database.bin file consists of a collection of fixed length records. Nothing more. More precisely, records are grouped in pages and, if needed, some padding will be added to the end of each page. index-gen Then the database file will be sorted by a column and rewritten. Based upont it, the program will build a sorted index binary file where each record will represent all records belonging to a single page. Actually, only single level indexing is supoorted. isam Finally, this executable will load the index and database files for support search queries and range selections. Also, this is my CMakeLists.txt cmake_minimum_required(VERSION 3.0.0) project(isam VERSION 0.1.0) include(CTest) enable_testing() add_executable(csv2bin csv2bin.cpp record.cpp) add_executable(index-gen index-gen.cpp record.cpp) add_executable(isam isam.cpp record.cpp lexer.cpp statement.cpp index.cpp pager.cpp database.cpp) set(CPACK_PROJECT_NAME ${PROJECT_NAME}) set(CPACK_PROJECT_VERSION ${PROJECT_VERSION}) include(CPack) References and useful links Connor Stack. db_tutorial Bjarne Stroustrup. The C++ Programming Language (4th edition) Grust, Torsten (Summer 2013). Tree-Structured Indexing: ISAM and B+-trees Compiler Explorer: https://godbolt.org/","title":"What is useless_isam ?"},{"location":"#what-is-useless_isam","text":"I was working on a C++ implementation of db_tutorial made by cstack as a pet project for my portfolio when I started to get hardy time on the B+Tree implementation section. After learning about B-Tree and B+Tree, I was still struggling with indexing and persistence on files. So I decided to switch to something easier and casually bumped into ISAM indexing.","title":"What is useless_isam ?"},{"location":"#why-useless","text":"Because with this project you can't insert new records. So it's a read only database. Just basic search queries and nothing else. Also, record columns are hard-coded within the source code. So neither CREAT TABLE statement type for column definition. Quite useless, don't you agree?","title":"Why useless?"},{"location":"#well-maybe-not-so-much-useless","text":"I like writing code and I am a C++ lover, so this small and simple project is ideal to put some things I learned until now in practice. Goal, I hope, is to produce a clean and well-written code and not something like if it compile and works then it's fine, no matter how it is made . Some keywords covered by this project are database isam indexing parsing lexer paging file manipulation paging caching cmake tokens record exception handling and I hope there will be more in the future.","title":"Well, maybe not so much useless..."},{"location":"#overvew","text":"ISAM is used to fast retrieve data from a database. So I decided to use a binary file for storing the dataset because it allows random access to records. Also, we need a dataset to populate our database. And don't forget that the database must be sorted in order to create an index file and support range selections. Let's put in order... generate a database binary file from a dataset sort the database binary file by a column generate the index binary file So I decided to archieve these points with three separate executables.","title":"Overvew"},{"location":"#csv2bin","text":"The program will use a textual dataset to build a database.bin file consists of a collection of fixed length records. Nothing more. More precisely, records are grouped in pages and, if needed, some padding will be added to the end of each page.","title":"csv2bin"},{"location":"#index-gen","text":"Then the database file will be sorted by a column and rewritten. Based upont it, the program will build a sorted index binary file where each record will represent all records belonging to a single page. Actually, only single level indexing is supoorted.","title":"index-gen"},{"location":"#isam","text":"Finally, this executable will load the index and database files for support search queries and range selections. Also, this is my CMakeLists.txt cmake_minimum_required(VERSION 3.0.0) project(isam VERSION 0.1.0) include(CTest) enable_testing() add_executable(csv2bin csv2bin.cpp record.cpp) add_executable(index-gen index-gen.cpp record.cpp) add_executable(isam isam.cpp record.cpp lexer.cpp statement.cpp index.cpp pager.cpp database.cpp) set(CPACK_PROJECT_NAME ${PROJECT_NAME}) set(CPACK_PROJECT_VERSION ${PROJECT_VERSION}) include(CPack)","title":"isam"},{"location":"#references-and-useful-links","text":"Connor Stack. db_tutorial Bjarne Stroustrup. The C++ Programming Language (4th edition) Grust, Torsten (Summer 2013). Tree-Structured Indexing: ISAM and B+-trees Compiler Explorer: https://godbolt.org/","title":"References and useful links"},{"location":"part1/","text":"Part 1 The dataset First thing to do is to select a dataset and, in case, adapt it for our purpose. After thinking a little about it, I endend up with a banal world cities dataset. I downloaded it somewhere on the net (don't remember) and made some adjustments like columns removal and representation edits. The cities.csv dataset consists of 140.895 rows separated by newline. Each row consists of 9 columns separated by semicolon. In dept Position Name Type Min/max/length C++ type C++ size 1 Geoname ID Positive integer max: 12.514.312 int 4 2 ASCII Name String max length: 69 char[70] 70 3 Country Code 2 character string fixed length: 2 char[3] 3 4 Country Name String max length: 38 char[39] 39 5 Population Positive integer max: 22.315.474 int 4 6 DEM Signed integer [-9.999, 5.622] int 4 7 Timezone String max length: 30 char[31] 31 8 Latitude String max length: 8 char[9] 9 9 Longitude String max length: 8 char[9] 9 Total 173 bytes Instead of storing a positive integer to a unsigned variable, we can safely use a int type beacause 1 INT_MAX = 2.14.748.364 (on my machine) is less than the max possible value for Geoname ID and Population attributes. You may think that the total size of a row is 173 bytes but you can't be sure until you check the output of sizeof() operator. Let's use Compiler Explorer (using x86-64 gcc 12.2) #include <iostream> struct Record { int id; char name[70]; char country_code[3]; char country_name[39]; int population; int dem; char timezone[31]; char latitude[9]; char longitude[9]; }; int main() { std::cout << sizeof(Record) << \"\\n\"; } Output: Program returned: 0 Program stdout 176 Why sizeof(Record) returns 176? According to Stroustrup 2 : An object doesn\u2019t just need enough storage to hold its representation. In addition, on some machine architectures, the bytes used to hold it must have proper alignment for the hardware to access it efficiently (or in extreme cases to access it at all). For example, a 4-byte int often has to be aligned on a word (4-byte) boundary, and sometimes an 8-byte double has to be aligned on a word (8-byte) boundary. Of course, this is all very implementation specific, and for most programmers completely implicit. You can write good C++ code for decades without needing to be explicit about alignment. Where alignment most often becomes visible is in object layouts: sometimes struct s contain \u2018\u2018holes\u2019\u2019 to improve alignment (\u00a78.2.1). The sum of a struct (or class ) attribute members is't always equal to the in-memory size of due to alignment optimizations that are machine-dependent. So you have to check out the previouse code with your compiler. Also, even though we are using fundamental types, their size are still machine-dependent 3 . In fact: Some of the aspects of C++\u2019s fundamental types, such as the size of an int , are implementation-defined. Similarly, the int type is supposed to be chosen to be the most suitable for holding and manipulating integers on a given computer; it is typically a 4-byte (32-bit) word. It is unwise to assume more. For example, there are machines with 32-bit char s. This is interesting but also quite problematic. You may experience different sizes. If we want to be strict, we should use int32_t instead of int (including the <cstdint> header) and char8_t instead of char (using the -std=c++20 compiler flag). But this problem will not be addressed now. Since most systems are similar to my machine (a typical laptop with Intel cpu) we will assume (wrongly!) that data types and sizes are those point out in the previous table. record.h Now we can discuss some code. Let's take a look at record.h struct Record { int id; char name[70]; char country_code[3]; char country_name[39]; int population; int dem; char timezone[31]; char latitude[9]; char longitude[9]; Record() = default; Record(const Record&); Record& operator=(const Record&); }; Surely we need a copy constructor and an assignent operator . Default copy costructor will copy variables and pointers and this would be really bad. In this example, the assignment operator is almost identical to copy constructor because the struct does not holds resource like dynamic memory. Record::Record(const Record& copy): id{copy.id}, population{copy.population}, dem{copy.dem} { strcpy(name, copy.name); strcpy(country_code, copy.country_code); strcpy(country_name, copy.country_name); strcpy(timezone, copy.timezone); strcpy(latitude, copy.latitude); strcpy(longitude, copy.longitude); } Record& Record::operator=(const Record& copy) { if(this != &copy) { //Protection againts self-assignment id = copy.id; strcpy(name, copy.name); strcpy(country_code, copy.country_code); strcpy(country_name, copy.country_name); population = copy.population; dem = copy.dem; strcpy(timezone, copy.timezone); strcpy(latitude, copy.latitude); strcpy(longitude, copy.longitude); } return *this; } No need to define a custom default constructor . The one generated by the compiler is fine. But since we defined a custom copy constructor, the generation of default constructor is suppressed. So we need to get it back using =default . Remember that you can possibly initialize the struct using the {} notation. A summary about default operations generation rules can be found at the Marius Bancila's Blog . https://en.cppreference.com/w/cpp/types/climits \u21a9 from The C++ Programming Language, 4th edition, \u00a76.2.9 \u21a9 from The C++ Programming Language, 4th edition, \u00a76.2.8 \u21a9","title":"Part 1"},{"location":"part1/#part-1","text":"","title":"Part 1"},{"location":"part1/#the-dataset","text":"First thing to do is to select a dataset and, in case, adapt it for our purpose. After thinking a little about it, I endend up with a banal world cities dataset. I downloaded it somewhere on the net (don't remember) and made some adjustments like columns removal and representation edits. The cities.csv dataset consists of 140.895 rows separated by newline. Each row consists of 9 columns separated by semicolon. In dept Position Name Type Min/max/length C++ type C++ size 1 Geoname ID Positive integer max: 12.514.312 int 4 2 ASCII Name String max length: 69 char[70] 70 3 Country Code 2 character string fixed length: 2 char[3] 3 4 Country Name String max length: 38 char[39] 39 5 Population Positive integer max: 22.315.474 int 4 6 DEM Signed integer [-9.999, 5.622] int 4 7 Timezone String max length: 30 char[31] 31 8 Latitude String max length: 8 char[9] 9 9 Longitude String max length: 8 char[9] 9 Total 173 bytes Instead of storing a positive integer to a unsigned variable, we can safely use a int type beacause 1 INT_MAX = 2.14.748.364 (on my machine) is less than the max possible value for Geoname ID and Population attributes. You may think that the total size of a row is 173 bytes but you can't be sure until you check the output of sizeof() operator. Let's use Compiler Explorer (using x86-64 gcc 12.2) #include <iostream> struct Record { int id; char name[70]; char country_code[3]; char country_name[39]; int population; int dem; char timezone[31]; char latitude[9]; char longitude[9]; }; int main() { std::cout << sizeof(Record) << \"\\n\"; } Output: Program returned: 0 Program stdout 176 Why sizeof(Record) returns 176? According to Stroustrup 2 : An object doesn\u2019t just need enough storage to hold its representation. In addition, on some machine architectures, the bytes used to hold it must have proper alignment for the hardware to access it efficiently (or in extreme cases to access it at all). For example, a 4-byte int often has to be aligned on a word (4-byte) boundary, and sometimes an 8-byte double has to be aligned on a word (8-byte) boundary. Of course, this is all very implementation specific, and for most programmers completely implicit. You can write good C++ code for decades without needing to be explicit about alignment. Where alignment most often becomes visible is in object layouts: sometimes struct s contain \u2018\u2018holes\u2019\u2019 to improve alignment (\u00a78.2.1). The sum of a struct (or class ) attribute members is't always equal to the in-memory size of due to alignment optimizations that are machine-dependent. So you have to check out the previouse code with your compiler. Also, even though we are using fundamental types, their size are still machine-dependent 3 . In fact: Some of the aspects of C++\u2019s fundamental types, such as the size of an int , are implementation-defined. Similarly, the int type is supposed to be chosen to be the most suitable for holding and manipulating integers on a given computer; it is typically a 4-byte (32-bit) word. It is unwise to assume more. For example, there are machines with 32-bit char s. This is interesting but also quite problematic. You may experience different sizes. If we want to be strict, we should use int32_t instead of int (including the <cstdint> header) and char8_t instead of char (using the -std=c++20 compiler flag). But this problem will not be addressed now. Since most systems are similar to my machine (a typical laptop with Intel cpu) we will assume (wrongly!) that data types and sizes are those point out in the previous table.","title":"The dataset"},{"location":"part1/#recordh","text":"Now we can discuss some code. Let's take a look at record.h struct Record { int id; char name[70]; char country_code[3]; char country_name[39]; int population; int dem; char timezone[31]; char latitude[9]; char longitude[9]; Record() = default; Record(const Record&); Record& operator=(const Record&); }; Surely we need a copy constructor and an assignent operator . Default copy costructor will copy variables and pointers and this would be really bad. In this example, the assignment operator is almost identical to copy constructor because the struct does not holds resource like dynamic memory. Record::Record(const Record& copy): id{copy.id}, population{copy.population}, dem{copy.dem} { strcpy(name, copy.name); strcpy(country_code, copy.country_code); strcpy(country_name, copy.country_name); strcpy(timezone, copy.timezone); strcpy(latitude, copy.latitude); strcpy(longitude, copy.longitude); } Record& Record::operator=(const Record& copy) { if(this != &copy) { //Protection againts self-assignment id = copy.id; strcpy(name, copy.name); strcpy(country_code, copy.country_code); strcpy(country_name, copy.country_name); population = copy.population; dem = copy.dem; strcpy(timezone, copy.timezone); strcpy(latitude, copy.latitude); strcpy(longitude, copy.longitude); } return *this; } No need to define a custom default constructor . The one generated by the compiler is fine. But since we defined a custom copy constructor, the generation of default constructor is suppressed. So we need to get it back using =default . Remember that you can possibly initialize the struct using the {} notation. A summary about default operations generation rules can be found at the Marius Bancila's Blog . https://en.cppreference.com/w/cpp/types/climits \u21a9 from The C++ Programming Language, 4th edition, \u00a76.2.9 \u21a9 from The C++ Programming Language, 4th edition, \u00a76.2.8 \u21a9","title":"record.h"},{"location":"part2/","text":"Part 2 We need to take the csv dataset cities.csv as input and generate a binary file. We should call it databse.bin . Next, we will use this one with index-gen executable in order to generate an index binary file index.bin . For now, it's bettere to save to a file all those filenames. Let's call it params.h : #define DATASET_FILENAME \"../cities.csv\" #define DATABASE_FILENAME \"../database.bin\" #define INDEX_FILENAME \"../index.bin\" I am using CMake with Visual Studio Code. In doing so, it will be faster to compile and execute the code during the development. Organization of database file We would read all records from cities.csv and write them to database.bin like a simply collection of Record s. But we want to take advantage of paging to improve performance. This will introduce just a bit of complexity. First, add to params.h the line #define PAGE_SIZE 4096 This is usually the page size in most systems. So, if sizeof(Record) = 176 bytes, and PAGE_SIZE is 4096, each paga will contains PAGE_SIZE / sizeof(Record) = 23 records with PAGE_SIZE % sizeof(Record) = 48 overhead byte remaining. csv2bin The source csv2bin.cpp simply reads each row from DATASET_FILENAME associated input stream, save it in a Record variable and append it to DATABASE_FILENAME associated output stream. Each 23 reads we have to write 48 byte to finish a page so const unsigned records_per_page{ PAGE_SIZE / sizeof(Record) }; //23 const unsigned overhead_byte_length{ PAGE_SIZE % sizeof(Record) }; //48 byte const char overhead_data[overhead_byte_length]{0}; size_t count{0}; //Record reads counter while(!input_file.eof()) { std::getline(input_file, row, '\\n'); //extracts a row /** * Save a row/line to Record variable */ output_file.write(reinterpret_cast<char*>(&record), sizeof(Record)); count += 1; if( (count % records_per_page) == 0) { //each 23 reads output_file.write(overhead_data, overhead_byte_length); //finish a page } } //end while-loop And this is the core idea. Extracting attributes from a row Each column is separate by a ; delimiter and we are storing an entire row to a std::string class type. So let's take advantage from the C++ standard library using find() 1 and substr() 2 methods. We could do something like this for int type std::string attr; next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); column = strtoul(attr.c_str(), nullptr, 10); last_pos = next_pos + 1; where column is the attribute extracted and converted to the appropriate type. Same for a null-terminated char array next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); strcpy(column, attr.c_str()); last_pos = next_pos + 1; Instead of repeating these instructions group 9 times inside the main() , we could use functions, overloading and template to improve the code quality, maintainability and readability. First, the two versions only differs for the extracting instruction, so template<typename T> void get(const std::string& row, const std::string delim, size_t& last_pos, size_t& next_pos, T& column) { std::string attr; next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); extract(column, attr); //<-- save attribute to record last_pos = next_pos + 1; } and then we take advantage of function overloading with void extract(int& to, const std::string& from) { to = strtoul(from.c_str(), nullptr, 10); } void extract(char* to, const std::string& from) { strcpy(to, from.c_str()); } Error handling It can be archieved by catching exceptions or traditional error handling. First, we can avoid exceptions for the input stream and be sure to enable them for the output stream input_file.exceptions(std::ifstream::goodbit); output_file.exceptions(std::ofstream::failbit); For example, if a stream fails to open, it will be in the bad state. You can check it with if(!input_file || !output_file) { std::clog << \"Error opening \" << DATASET_FILENAME << \" or \" DATABASE_FILENAME << \"\\n\"; return EXIT_FAILURE; } We had to check every time if there are reading errors after calling getline() with 3 if(input_file.fail()) { std::clog << \"Error occurred while reading from \" << DATASET_FILENAME << \"\\n\"; return EXIT_FAILURE; } Finally, write instructions to the output file are near so we can group them inside a try block try { output_file.write(reinterpret_cast<char*>(&record), sizeof(Record)); count += 1; if( (count % records_per_page) == 0) { output_file.write(overhead_data, overhead_byte_length); } } catch(std::ofstream::failure& e) { std::clog << \"Error occurred while writing on \" << DATABASE_FILENAME << \": \" << e.what() << \"\\n\"; return EXIT_FAILURE; } Anyway, this is not the best way to use exceptions. An exception is handled in order to recover from run-time errors and with the RAII technique 4 . Results Well, not very encouraging. We obtained a file of 25.091.696 byte aganist the original one of 10.395.430 byte: an increment of +141,37%. A bit too much... We sacrificed a lot of memory space with access speed. This will be discussed later. Be careful that the last page is partial: this could be a problem when it's time to read it because the size is less than PAGE_SIZE = 4096 byte. https://en.cppreference.com/w/cpp/string/basic_string/find \u21a9 https://en.cppreference.com/w/cpp/string/basic_string/substr \u21a9 https://en.cppreference.com/w/cpp/string/basic_string/getline \u21a9 Bjarne Stroustrup. The C++ Programming Language, 4th edition, \u00a713.1 \u21a9","title":"Part 2"},{"location":"part2/#part-2","text":"We need to take the csv dataset cities.csv as input and generate a binary file. We should call it databse.bin . Next, we will use this one with index-gen executable in order to generate an index binary file index.bin . For now, it's bettere to save to a file all those filenames. Let's call it params.h : #define DATASET_FILENAME \"../cities.csv\" #define DATABASE_FILENAME \"../database.bin\" #define INDEX_FILENAME \"../index.bin\" I am using CMake with Visual Studio Code. In doing so, it will be faster to compile and execute the code during the development.","title":"Part 2"},{"location":"part2/#organization-of-database-file","text":"We would read all records from cities.csv and write them to database.bin like a simply collection of Record s. But we want to take advantage of paging to improve performance. This will introduce just a bit of complexity. First, add to params.h the line #define PAGE_SIZE 4096 This is usually the page size in most systems. So, if sizeof(Record) = 176 bytes, and PAGE_SIZE is 4096, each paga will contains PAGE_SIZE / sizeof(Record) = 23 records with PAGE_SIZE % sizeof(Record) = 48 overhead byte remaining.","title":"Organization of database file"},{"location":"part2/#csv2bin","text":"The source csv2bin.cpp simply reads each row from DATASET_FILENAME associated input stream, save it in a Record variable and append it to DATABASE_FILENAME associated output stream. Each 23 reads we have to write 48 byte to finish a page so const unsigned records_per_page{ PAGE_SIZE / sizeof(Record) }; //23 const unsigned overhead_byte_length{ PAGE_SIZE % sizeof(Record) }; //48 byte const char overhead_data[overhead_byte_length]{0}; size_t count{0}; //Record reads counter while(!input_file.eof()) { std::getline(input_file, row, '\\n'); //extracts a row /** * Save a row/line to Record variable */ output_file.write(reinterpret_cast<char*>(&record), sizeof(Record)); count += 1; if( (count % records_per_page) == 0) { //each 23 reads output_file.write(overhead_data, overhead_byte_length); //finish a page } } //end while-loop And this is the core idea.","title":"csv2bin"},{"location":"part2/#extracting-attributes-from-a-row","text":"Each column is separate by a ; delimiter and we are storing an entire row to a std::string class type. So let's take advantage from the C++ standard library using find() 1 and substr() 2 methods. We could do something like this for int type std::string attr; next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); column = strtoul(attr.c_str(), nullptr, 10); last_pos = next_pos + 1; where column is the attribute extracted and converted to the appropriate type. Same for a null-terminated char array next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); strcpy(column, attr.c_str()); last_pos = next_pos + 1; Instead of repeating these instructions group 9 times inside the main() , we could use functions, overloading and template to improve the code quality, maintainability and readability. First, the two versions only differs for the extracting instruction, so template<typename T> void get(const std::string& row, const std::string delim, size_t& last_pos, size_t& next_pos, T& column) { std::string attr; next_pos = row.find(delim, last_pos); attr = row.substr(last_pos, next_pos-last_pos); extract(column, attr); //<-- save attribute to record last_pos = next_pos + 1; } and then we take advantage of function overloading with void extract(int& to, const std::string& from) { to = strtoul(from.c_str(), nullptr, 10); } void extract(char* to, const std::string& from) { strcpy(to, from.c_str()); }","title":"Extracting attributes from a row"},{"location":"part2/#error-handling","text":"It can be archieved by catching exceptions or traditional error handling. First, we can avoid exceptions for the input stream and be sure to enable them for the output stream input_file.exceptions(std::ifstream::goodbit); output_file.exceptions(std::ofstream::failbit); For example, if a stream fails to open, it will be in the bad state. You can check it with if(!input_file || !output_file) { std::clog << \"Error opening \" << DATASET_FILENAME << \" or \" DATABASE_FILENAME << \"\\n\"; return EXIT_FAILURE; } We had to check every time if there are reading errors after calling getline() with 3 if(input_file.fail()) { std::clog << \"Error occurred while reading from \" << DATASET_FILENAME << \"\\n\"; return EXIT_FAILURE; } Finally, write instructions to the output file are near so we can group them inside a try block try { output_file.write(reinterpret_cast<char*>(&record), sizeof(Record)); count += 1; if( (count % records_per_page) == 0) { output_file.write(overhead_data, overhead_byte_length); } } catch(std::ofstream::failure& e) { std::clog << \"Error occurred while writing on \" << DATABASE_FILENAME << \": \" << e.what() << \"\\n\"; return EXIT_FAILURE; } Anyway, this is not the best way to use exceptions. An exception is handled in order to recover from run-time errors and with the RAII technique 4 .","title":"Error handling"},{"location":"part2/#results","text":"Well, not very encouraging. We obtained a file of 25.091.696 byte aganist the original one of 10.395.430 byte: an increment of +141,37%. A bit too much... We sacrificed a lot of memory space with access speed. This will be discussed later. Be careful that the last page is partial: this could be a problem when it's time to read it because the size is less than PAGE_SIZE = 4096 byte. https://en.cppreference.com/w/cpp/string/basic_string/find \u21a9 https://en.cppreference.com/w/cpp/string/basic_string/substr \u21a9 https://en.cppreference.com/w/cpp/string/basic_string/getline \u21a9 Bjarne Stroustrup. The C++ Programming Language, 4th edition, \u00a713.1 \u21a9","title":"Results"},{"location":"part3/","text":"Part 3 Records stored in database.bin are not sorted by any column. So, it is just an agglomerate of Records with some padding, grouped by pages. Not very useful for our purpose. We need to to select a proper column as a primary key, let's say A , in order to have an A -sorted data file. Next step is to generate an index file so it can be used to access to index entry: it is an ordered pair (k i , p i ) where k i is the minimal value inside the page p i , witch contains a certain number of Records. Since a Record is 176 byte long, and a page holds 23 Records, the key k i of page p i belonging to the Record with the A-column value is less than any other inside the same page and the next ones. You can found the code described in this section in index-gen.cpp . Getting, sorting and saving data We need to Fetch all Records from the database.bin to a vector Sort them by a column Write the sorted vector to database.bin Fortunally, we can take advantage of std::vector and std::sort() provided by the C++ Standard Library. load_data() The function declaration is std::vector<Record> load_data(const std::string& filename) It will set up a std::vector with all Records loaded from the database.bin and will returns it. Quite simple. We need to know how many Records are present inside the database. So we will open the file with the std::ios_base::ate flag in order to move the file pointer position at the end of file. Then, the tellg() method will returns the file byte size, say db_size . Since PAGE_SIZE = 4096 and sizeof_record = sizeof(Record) with records_per_page = PAGE_SIZE / sizeof_record provide the number of records in a single page with page_count = db_size / PAGE_SIZE provide get the number of pages page_count * records_per_page provide the number of records in the database with remaining_bytes = db_size % PAGE_SIZE provide the remaing byte of the partial page remaining_bytes / sizeof_record provide the number of records in the last page So the sum of records is unsigned int record_count{ (page_count * records_per_page) + (remaining_bytes / sizeof_record) }; We will pass this value to std::vector constructor. About narrowing conversion We want to avoid as much as possible implicit conversions that can lead to not only loss of data but also values falsification like assigning a -1 value to a unsigned variable by mistake. Compiler can warn you when and where a narrowing conversion occour and we had to take a closer look in those points. Bjarne debate abount implicit type conversion in The C++ Programming Language, \u0300\u00a710.5. const std::streamoff db_size{file.tellg()}; if(db_size == -1) { std::clog << \"Error getting file size of \" << filename << \"\\n\"; exit(EXIT_FAILURE); } tellg() returns a std::streampos, aka long long, so the return value will be stored in a same type variable. After checking if no failure accur, we can assume that is a positive value and go on. const unsigned int sizeof_record{sizeof(Record)}; Compiler know that sizeof(Record) fits inside an unsigned int so it won't issue any narrowing conversion message. const unsigned int records_per_page{ PAGE_SIZE / sizeof_record }; Almost the same for this. const unsigned int page_count( db_size / PAGE_SIZE ); const unsigned remaining_bytes( db_size % PAGE_SIZE ); In order to avoid narrowing conversion messages by compiler, we had to initialize the two variables without the {}-initializer notation. Fortunally, we already checked if db_size is positive so we can safety do this. The remainder of the function is quite self-explanatory. Moving semantics You should have noticed that the function is returning a local object. If you don't know about moving semantics , you are probably thinking that the function is returning a vector object by value (a copy). Well, if a Record size is 176 byte, and the database has more than 140 thousand of Records, this would be very problematic... Fortunally, C++11 introduced rvalue references and move semantics which let you move an object outside of a function. So, in brief, the vector is not copied but moved and this is almost costless. Some resources I found useful about move semantics: Bjarne Stroustrup. The C++ Programming Language. \u00a73.3.2, \u00a76.4.1, \u00a77.7.2, \u00a717.1, \u00a717.5.2 The Cherno on YouTube lvalues and rvalues in C++: https://youtu.be/fbYknr-HPYE Move Semantics in C++: https://youtu.be/ehMg6zvXuMY fredoverflow on Stack Overflow (the best in my opinion): https://stackoverflow.com/questions/3106110/what-is-move-semantics Sorting and writing data We can take advantage of the standard library for sorting data with lambda expression 1 . In the main() function, std::vector<Record> database{load_data(DATABASE_FILENAME)}; std::sort(database.begin(), database.end(), [](const Record& a, const Record& b) { return a.id < b.id; } ); Writing data should not be problematic. Generating index file Same for the database, we will generate a std::vector of index entries e write it to a file index.bin . To represent a pair of (key, page), I decide to use the std::pair from the standard library. This class is a template, so we can save time putting using index_entry_t = std::pair<int, int>; in params.h . Setting up the index should not be so hard std::vector<index_entry_t> index(num_of_pages); for(int page = 0; page < num_of_pages; page += 1) { index[page].first = database[page*records_per_page].id; index[page].second = page; } We take the first Record of each page and build the index entry vector jumping records_per_page == 23 Records each time. Last, we save the vector to a file like we already did before. About indexing and a bit of criticism This is a single level indexing with no paging: just a simple sequence of index_entry_t and no more. We obtained a file 49.008 byte big. It is bigger than a single page size chosen before. This results in a lot of RAM memory utilization because you will see, during the isam.exe implementation, that we will load the entire index file We could add paging support to the index file creation in order to reduce RAM utilization or we could also using multi-level index, recursively applying the index creation step. Bjarne Stroutrup. The C++ Programming Language, \u0300\u00a711.4 \u21a9","title":"Part 3"},{"location":"part3/#part-3","text":"Records stored in database.bin are not sorted by any column. So, it is just an agglomerate of Records with some padding, grouped by pages. Not very useful for our purpose. We need to to select a proper column as a primary key, let's say A , in order to have an A -sorted data file. Next step is to generate an index file so it can be used to access to index entry: it is an ordered pair (k i , p i ) where k i is the minimal value inside the page p i , witch contains a certain number of Records. Since a Record is 176 byte long, and a page holds 23 Records, the key k i of page p i belonging to the Record with the A-column value is less than any other inside the same page and the next ones. You can found the code described in this section in index-gen.cpp .","title":"Part 3"},{"location":"part3/#getting-sorting-and-saving-data","text":"We need to Fetch all Records from the database.bin to a vector Sort them by a column Write the sorted vector to database.bin Fortunally, we can take advantage of std::vector and std::sort() provided by the C++ Standard Library.","title":"Getting, sorting and saving data"},{"location":"part3/#load_data","text":"The function declaration is std::vector<Record> load_data(const std::string& filename) It will set up a std::vector with all Records loaded from the database.bin and will returns it. Quite simple. We need to know how many Records are present inside the database. So we will open the file with the std::ios_base::ate flag in order to move the file pointer position at the end of file. Then, the tellg() method will returns the file byte size, say db_size . Since PAGE_SIZE = 4096 and sizeof_record = sizeof(Record) with records_per_page = PAGE_SIZE / sizeof_record provide the number of records in a single page with page_count = db_size / PAGE_SIZE provide get the number of pages page_count * records_per_page provide the number of records in the database with remaining_bytes = db_size % PAGE_SIZE provide the remaing byte of the partial page remaining_bytes / sizeof_record provide the number of records in the last page So the sum of records is unsigned int record_count{ (page_count * records_per_page) + (remaining_bytes / sizeof_record) }; We will pass this value to std::vector constructor.","title":"load_data()"},{"location":"part3/#about-narrowing-conversion","text":"We want to avoid as much as possible implicit conversions that can lead to not only loss of data but also values falsification like assigning a -1 value to a unsigned variable by mistake. Compiler can warn you when and where a narrowing conversion occour and we had to take a closer look in those points. Bjarne debate abount implicit type conversion in The C++ Programming Language, \u0300\u00a710.5. const std::streamoff db_size{file.tellg()}; if(db_size == -1) { std::clog << \"Error getting file size of \" << filename << \"\\n\"; exit(EXIT_FAILURE); } tellg() returns a std::streampos, aka long long, so the return value will be stored in a same type variable. After checking if no failure accur, we can assume that is a positive value and go on. const unsigned int sizeof_record{sizeof(Record)}; Compiler know that sizeof(Record) fits inside an unsigned int so it won't issue any narrowing conversion message. const unsigned int records_per_page{ PAGE_SIZE / sizeof_record }; Almost the same for this. const unsigned int page_count( db_size / PAGE_SIZE ); const unsigned remaining_bytes( db_size % PAGE_SIZE ); In order to avoid narrowing conversion messages by compiler, we had to initialize the two variables without the {}-initializer notation. Fortunally, we already checked if db_size is positive so we can safety do this. The remainder of the function is quite self-explanatory.","title":"About narrowing conversion"},{"location":"part3/#moving-semantics","text":"You should have noticed that the function is returning a local object. If you don't know about moving semantics , you are probably thinking that the function is returning a vector object by value (a copy). Well, if a Record size is 176 byte, and the database has more than 140 thousand of Records, this would be very problematic... Fortunally, C++11 introduced rvalue references and move semantics which let you move an object outside of a function. So, in brief, the vector is not copied but moved and this is almost costless. Some resources I found useful about move semantics: Bjarne Stroustrup. The C++ Programming Language. \u00a73.3.2, \u00a76.4.1, \u00a77.7.2, \u00a717.1, \u00a717.5.2 The Cherno on YouTube lvalues and rvalues in C++: https://youtu.be/fbYknr-HPYE Move Semantics in C++: https://youtu.be/ehMg6zvXuMY fredoverflow on Stack Overflow (the best in my opinion): https://stackoverflow.com/questions/3106110/what-is-move-semantics","title":"Moving semantics"},{"location":"part3/#sorting-and-writing-data","text":"We can take advantage of the standard library for sorting data with lambda expression 1 . In the main() function, std::vector<Record> database{load_data(DATABASE_FILENAME)}; std::sort(database.begin(), database.end(), [](const Record& a, const Record& b) { return a.id < b.id; } ); Writing data should not be problematic.","title":"Sorting and writing data"},{"location":"part3/#generating-index-file","text":"Same for the database, we will generate a std::vector of index entries e write it to a file index.bin . To represent a pair of (key, page), I decide to use the std::pair from the standard library. This class is a template, so we can save time putting using index_entry_t = std::pair<int, int>; in params.h . Setting up the index should not be so hard std::vector<index_entry_t> index(num_of_pages); for(int page = 0; page < num_of_pages; page += 1) { index[page].first = database[page*records_per_page].id; index[page].second = page; } We take the first Record of each page and build the index entry vector jumping records_per_page == 23 Records each time. Last, we save the vector to a file like we already did before.","title":"Generating index file"},{"location":"part3/#about-indexing-and-a-bit-of-criticism","text":"This is a single level indexing with no paging: just a simple sequence of index_entry_t and no more. We obtained a file 49.008 byte big. It is bigger than a single page size chosen before. This results in a lot of RAM memory utilization because you will see, during the isam.exe implementation, that we will load the entire index file We could add paging support to the index file creation in order to reduce RAM utilization or we could also using multi-level index, recursively applying the index creation step. Bjarne Stroutrup. The C++ Programming Language, \u0300\u00a711.4 \u21a9","title":"About indexing and a bit of criticism"},{"location":"part4/","text":"Part 4 Warning: this will be the most substantial part. Our isam.exe will be the concrete ISAM reader, supporting single / range selection of Records. We will need to take care of the following problems: index file loading and search support on it database file loading and single / multi Records retrieval (through a \"cache-paging system\") a decent user interface able to understand simple queries Let's start with the latter... Parser class We need something able to understand queries like SELECT [id] SELECT [range] where [range] is something like [start-id] \u2014 [end-id] . Not a big deal. Maybe calling it a \"parser\" is a bit too much. Anyway, it will be an ultra minimalist parser. In fact, the grammar is quite simple statement \u2192 SELECT [expression] expression \u2192 [id] [id] - [id] id \u2192 POSITIVE INTEGER This style of syntax analysis is called recursive descent 1 . statement , expression and id are called grammar production : for each one, there is a function. Usually, there is a Lexer, a Parser and a Symbol Table. But our grammar is really simple so we don't need the last one. From the famous Dragon Book (\u00a73.1)... Based on the grammar and the model above, let's start defining a Token class in token.h enum class Token_type { SELECT, RANGE_OPERATOR, POSITIVE_INTEGER, end //end of input }; struct Token { Token_type type; std::string value; }; The next step is the Lexer (sometime called Scanner) in lexer.h class Lexer { std::stringstream input; Token current_token; public: Lexer(const std::string& in): input(in), current_token{Token_type::end} { }; Token get(); //consume the next token from the origin and return it const Token& current() const { return current_token; }; //only returns the current token }; The meaning of the Lexer class is to hide the origin (in this case, the std::cin standard input), showing to the Parser a sequence of Token and no more. So the Lexer had to recognize a sequence of character and transform it in a Token sequence. This is archieved with the get() function implemented in lexer.cpp : it should be easy to understand. Now it's Parser 's turn. It is a Statement class that gets Tokens from the Lexer and builds an internal representation for the subsequent action class Statement { enum Type { SELECT_SINGLE, SELECT_RANGE }; Type statement_type; int start_id; int end_id; Lexer lexer; public: Statement(const std::string&); void expression(); int id(); std::vector<Record> execute(Database& database); }; If you take a look at statement.cpp , you will notice that the mothods expression() and id() match the grammar productions and they are only called inside the Statement() constructor. This is also an attempt to follow the RAII rule: if a problem occur parsing the user input, the constructor fails and there is no risk of creating a partially initialized object. Said that, we can start thinking about the main() function with the REPL loop 2 (a classic). int main(int argc, char const *argv[]) { std::string input; //sql statement from standard input bool exit{false}; // Database database{INDEX_FILENAME, DATABASE_FILENAME}; //REPL while(!exit) { std::cout << \"isam > \"; std::getline(std::cin, input, '\\n'); if(input == \".exit\" || std::cin.eof()) { exit = true; } else { Statement statement{input}; // std::vector<Record> res = statement.execute(database); // if(res.size()) { // for(auto& e: res) { //showing results // std::cout << e; // } // } // else { // std::cout << \"Found 0 records\\n\"; // } // } } return EXIT_SUCCESS; } Some sections are commented because it's too early to talk about them. Next we will talk about the commented sections. Index class This is preparatory to the Database class. We need a guy that help us to load index records from the index file to memory let us search for a key and get the page number Not so hard. So this is the interface and representation of Index class class Index { index_entry_t* index; int index_size; public: Index(const std::string&); ~Index() { if(index) delete[] index; }; int search(const unsigned int); int search_reverse(const unsigned int); //Suppressed Index(const Index&) = delete; Index(const Index&&) = delete; Index& operator=(const Index&) = delete; Index& operator=(Index&&) = delete; }; First of all, we suppress some implicit-defined member functions because they would be incorrect . We should have redefined them but, actually, we don't need this. The constructor simply loads index records from file The search() function finds the page number of first Record which key is bigger or equal to the argument. The search_reverse() is similar but it is used for range selection when searching for end-id . Pager class This is an attempt of introducing some sort of optimization through caching. When retrieving a Record, the entire page within which it resides is loaded in memory and stored until the end of program. In this way, if Records of the same page will be loaded much faster. The most important function is get_page() : if(num_page >= this->pages_size) { return nullptr; } checks if the argument is correct. if(pages[num_page]) { return pages[num_page]; } returns the page if it is already in memory. file.seekg(PAGE_SIZE*num_page); set the file input position at the start of selected page. pages[num_page] = new Page{num_page, records_to_fetch}; file.read( reinterpret_cast<char*>(pages[num_page]->records), sizeof(Record)*records_to_fetch); allocate the page and read it from database file. Page class It represents a single page. Attributes are struct Page { Record* records; //Pointer to records array const int size; //Records array size const int page_pos; //Position of page in file (...) Cursor class This class is like a file pointer position. It allows to easily navigate through the database. It's like a very basic iterator of a Record. Let's see the representation. Default contructor makes a non valid cursor. class Cursor { Pager* pager; //a pointer to Page object const Page* page; //pointer to page of the Record public: const Record* record; //pointer to the Record unsigned int page_pos; //page position of the Record on file unsigned int array_pos; //Record position on Page class (...) First, a cursor is not valid when Cursor::record == nullptr . Then Cursor::operator bool() const { return (record) ? true : false; } Also, we need some comparison function bool Cursor::operator==(const Cursor& other) const { return (this->page_pos == other.page_pos && this->array_pos == other.array_pos) ? true : false; } bool Cursor::operator!=(const Cursor& other) const { return !this->operator==(other); } At this point, we can define a prefix increment operator Cursor& Cursor::operator++() . If we move forward the cursor, it refers to the next record of the database. What if the current record was the last from the page? if(++array_pos == page->size) { //last record of page page_pos += 1; array_pos = 0; } then we move to the first record (position zero) of the next page. And what if the page was the last? if(page_pos == page->size) { //se era l'ultima pagina this->record = nullptr; //invalido il cursore return *this; } it means that page_pos now is equal to Page::page_size so we reached the end (invalid cursor). Last, we need to computer the difference between two Cursor in terms of Records. So we create int Cursor::diff(const Cursor& other) . Database class The database class use the Index, Pager and Cursor classes to finalize a simplified database behaviour. Interface consist of two methods: one for single search and another for range selections. Single search The function Cursor Database::search(const int key) search for the record which the column named id is equal to the parameter key . First int page_num = this->index.search(key); if(page_num == -1) { return Cursor{}; } const Page* page = this->pager.get_page(page_num); try to locate the page that might contain the key. Then loads the page from file. int i{0}; while(i < pager.records_per_page && page->records[i].id != key) { i += 1; } if(i == pager.records_per_page) { //not found return Cursor{}; } else { return Cursor{&pager, page, &(page->records[i]), i, page_num}; } try to locate the record inside the page. If it does not exists, the function returns a invalid Cursor. Range selections The function std::pair<Cursor,Cursor> Database::search(const int start_key, const int end_key) search for all records which id is included in the range [ start_key , end_key ] . It returns a couple of Cursor referring to the first and the last element found. It's more complicated. A step at a time... const auto not_found = std::pair<Cursor,Cursor>{ Cursor{}, Cursor{} }; this is a shortcut to the value not found used inside this function. int start_page_pos = this->index.search(start_key); if(start_page_pos == -1) { return not_found; } const Page* start_page_ptr = this->pager.get_page(start_page_pos); Like before, try to locate the page that might contain the key and loads the page from file. But this time is different because the page could contain elements less than start_key . In this case we had to go to the next page int start_i = start_page_ptr->search_greater_equal(start_key); if(start_i == -1) { start_page_pos += 1; start_page_ptr = this->pager.get_page(start_page_pos); start_i = start_page_ptr->search_greater_equal(start_key); } The second part search for a key less or equal to end_key and is similar to the first one. Finally return std::pair{ Cursor{&pager, start_page_ptr, &(start_page_ptr->records[start_i]), start_page_pos, start_i}, Cursor{&pager, end_page_ptr, &(end_page_ptr->records[end_i]), end_page_pos, end_i} }; returns a range of records. Back to the Statement class Last step is to implement std::vector<Record> Statement::execute(Database& database) in statement.cpp . We store the result in a std::vector class: if no records are found, then we get an empty vector. First if(statement_type == Type::SELECT_SINGLE) { Cursor res = database.search(start_id); return (res) ? std::vector{*res.record} : std::vector<Record>(0); } quite self-explanatory. For range selections instead auto range = database.search(start_id, end_id); if(!range.first) { //se non trovato return std::vector<Record>(0); } no criptic expressions until here. Next, if there are some results std::vector<Record> results(range.first.diff(range.second) + 1); then constructs a vector with the number of records found int i{0}; while(range.first != range.second) { results[i++] = *range.first.record; ++range.first; } results[i] = *range.first.record; return results; this put each record inside the vector. Bjarne Stroustrup. The C++ Programming Language. \u00a710.2.1 \u21a9 https://cstack.github.io/db_tutorial/parts/part1.html \u21a9","title":"Part 4"},{"location":"part4/#part-4","text":"Warning: this will be the most substantial part. Our isam.exe will be the concrete ISAM reader, supporting single / range selection of Records. We will need to take care of the following problems: index file loading and search support on it database file loading and single / multi Records retrieval (through a \"cache-paging system\") a decent user interface able to understand simple queries Let's start with the latter...","title":"Part 4"},{"location":"part4/#parser-class","text":"We need something able to understand queries like SELECT [id] SELECT [range] where [range] is something like [start-id] \u2014 [end-id] . Not a big deal. Maybe calling it a \"parser\" is a bit too much. Anyway, it will be an ultra minimalist parser. In fact, the grammar is quite simple statement \u2192 SELECT [expression] expression \u2192 [id] [id] - [id] id \u2192 POSITIVE INTEGER This style of syntax analysis is called recursive descent 1 . statement , expression and id are called grammar production : for each one, there is a function. Usually, there is a Lexer, a Parser and a Symbol Table. But our grammar is really simple so we don't need the last one. From the famous Dragon Book (\u00a73.1)... Based on the grammar and the model above, let's start defining a Token class in token.h enum class Token_type { SELECT, RANGE_OPERATOR, POSITIVE_INTEGER, end //end of input }; struct Token { Token_type type; std::string value; }; The next step is the Lexer (sometime called Scanner) in lexer.h class Lexer { std::stringstream input; Token current_token; public: Lexer(const std::string& in): input(in), current_token{Token_type::end} { }; Token get(); //consume the next token from the origin and return it const Token& current() const { return current_token; }; //only returns the current token }; The meaning of the Lexer class is to hide the origin (in this case, the std::cin standard input), showing to the Parser a sequence of Token and no more. So the Lexer had to recognize a sequence of character and transform it in a Token sequence. This is archieved with the get() function implemented in lexer.cpp : it should be easy to understand. Now it's Parser 's turn. It is a Statement class that gets Tokens from the Lexer and builds an internal representation for the subsequent action class Statement { enum Type { SELECT_SINGLE, SELECT_RANGE }; Type statement_type; int start_id; int end_id; Lexer lexer; public: Statement(const std::string&); void expression(); int id(); std::vector<Record> execute(Database& database); }; If you take a look at statement.cpp , you will notice that the mothods expression() and id() match the grammar productions and they are only called inside the Statement() constructor. This is also an attempt to follow the RAII rule: if a problem occur parsing the user input, the constructor fails and there is no risk of creating a partially initialized object. Said that, we can start thinking about the main() function with the REPL loop 2 (a classic). int main(int argc, char const *argv[]) { std::string input; //sql statement from standard input bool exit{false}; // Database database{INDEX_FILENAME, DATABASE_FILENAME}; //REPL while(!exit) { std::cout << \"isam > \"; std::getline(std::cin, input, '\\n'); if(input == \".exit\" || std::cin.eof()) { exit = true; } else { Statement statement{input}; // std::vector<Record> res = statement.execute(database); // if(res.size()) { // for(auto& e: res) { //showing results // std::cout << e; // } // } // else { // std::cout << \"Found 0 records\\n\"; // } // } } return EXIT_SUCCESS; } Some sections are commented because it's too early to talk about them. Next we will talk about the commented sections.","title":"Parser class"},{"location":"part4/#index-class","text":"This is preparatory to the Database class. We need a guy that help us to load index records from the index file to memory let us search for a key and get the page number Not so hard. So this is the interface and representation of Index class class Index { index_entry_t* index; int index_size; public: Index(const std::string&); ~Index() { if(index) delete[] index; }; int search(const unsigned int); int search_reverse(const unsigned int); //Suppressed Index(const Index&) = delete; Index(const Index&&) = delete; Index& operator=(const Index&) = delete; Index& operator=(Index&&) = delete; }; First of all, we suppress some implicit-defined member functions because they would be incorrect . We should have redefined them but, actually, we don't need this. The constructor simply loads index records from file The search() function finds the page number of first Record which key is bigger or equal to the argument. The search_reverse() is similar but it is used for range selection when searching for end-id .","title":"Index class"},{"location":"part4/#pager-class","text":"This is an attempt of introducing some sort of optimization through caching. When retrieving a Record, the entire page within which it resides is loaded in memory and stored until the end of program. In this way, if Records of the same page will be loaded much faster. The most important function is get_page() : if(num_page >= this->pages_size) { return nullptr; } checks if the argument is correct. if(pages[num_page]) { return pages[num_page]; } returns the page if it is already in memory. file.seekg(PAGE_SIZE*num_page); set the file input position at the start of selected page. pages[num_page] = new Page{num_page, records_to_fetch}; file.read( reinterpret_cast<char*>(pages[num_page]->records), sizeof(Record)*records_to_fetch); allocate the page and read it from database file.","title":"Pager class"},{"location":"part4/#page-class","text":"It represents a single page. Attributes are struct Page { Record* records; //Pointer to records array const int size; //Records array size const int page_pos; //Position of page in file (...)","title":"Page class"},{"location":"part4/#cursor-class","text":"This class is like a file pointer position. It allows to easily navigate through the database. It's like a very basic iterator of a Record. Let's see the representation. Default contructor makes a non valid cursor. class Cursor { Pager* pager; //a pointer to Page object const Page* page; //pointer to page of the Record public: const Record* record; //pointer to the Record unsigned int page_pos; //page position of the Record on file unsigned int array_pos; //Record position on Page class (...) First, a cursor is not valid when Cursor::record == nullptr . Then Cursor::operator bool() const { return (record) ? true : false; } Also, we need some comparison function bool Cursor::operator==(const Cursor& other) const { return (this->page_pos == other.page_pos && this->array_pos == other.array_pos) ? true : false; } bool Cursor::operator!=(const Cursor& other) const { return !this->operator==(other); } At this point, we can define a prefix increment operator Cursor& Cursor::operator++() . If we move forward the cursor, it refers to the next record of the database. What if the current record was the last from the page? if(++array_pos == page->size) { //last record of page page_pos += 1; array_pos = 0; } then we move to the first record (position zero) of the next page. And what if the page was the last? if(page_pos == page->size) { //se era l'ultima pagina this->record = nullptr; //invalido il cursore return *this; } it means that page_pos now is equal to Page::page_size so we reached the end (invalid cursor). Last, we need to computer the difference between two Cursor in terms of Records. So we create int Cursor::diff(const Cursor& other) .","title":"Cursor class"},{"location":"part4/#database-class","text":"The database class use the Index, Pager and Cursor classes to finalize a simplified database behaviour. Interface consist of two methods: one for single search and another for range selections.","title":"Database class"},{"location":"part4/#single-search","text":"The function Cursor Database::search(const int key) search for the record which the column named id is equal to the parameter key . First int page_num = this->index.search(key); if(page_num == -1) { return Cursor{}; } const Page* page = this->pager.get_page(page_num); try to locate the page that might contain the key. Then loads the page from file. int i{0}; while(i < pager.records_per_page && page->records[i].id != key) { i += 1; } if(i == pager.records_per_page) { //not found return Cursor{}; } else { return Cursor{&pager, page, &(page->records[i]), i, page_num}; } try to locate the record inside the page. If it does not exists, the function returns a invalid Cursor.","title":"Single search"},{"location":"part4/#range-selections","text":"The function std::pair<Cursor,Cursor> Database::search(const int start_key, const int end_key) search for all records which id is included in the range [ start_key , end_key ] . It returns a couple of Cursor referring to the first and the last element found. It's more complicated. A step at a time... const auto not_found = std::pair<Cursor,Cursor>{ Cursor{}, Cursor{} }; this is a shortcut to the value not found used inside this function. int start_page_pos = this->index.search(start_key); if(start_page_pos == -1) { return not_found; } const Page* start_page_ptr = this->pager.get_page(start_page_pos); Like before, try to locate the page that might contain the key and loads the page from file. But this time is different because the page could contain elements less than start_key . In this case we had to go to the next page int start_i = start_page_ptr->search_greater_equal(start_key); if(start_i == -1) { start_page_pos += 1; start_page_ptr = this->pager.get_page(start_page_pos); start_i = start_page_ptr->search_greater_equal(start_key); } The second part search for a key less or equal to end_key and is similar to the first one. Finally return std::pair{ Cursor{&pager, start_page_ptr, &(start_page_ptr->records[start_i]), start_page_pos, start_i}, Cursor{&pager, end_page_ptr, &(end_page_ptr->records[end_i]), end_page_pos, end_i} }; returns a range of records.","title":"Range selections"},{"location":"part4/#back-to-the-statement-class","text":"Last step is to implement std::vector<Record> Statement::execute(Database& database) in statement.cpp . We store the result in a std::vector class: if no records are found, then we get an empty vector. First if(statement_type == Type::SELECT_SINGLE) { Cursor res = database.search(start_id); return (res) ? std::vector{*res.record} : std::vector<Record>(0); } quite self-explanatory. For range selections instead auto range = database.search(start_id, end_id); if(!range.first) { //se non trovato return std::vector<Record>(0); } no criptic expressions until here. Next, if there are some results std::vector<Record> results(range.first.diff(range.second) + 1); then constructs a vector with the number of records found int i{0}; while(range.first != range.second) { results[i++] = *range.first.record; ++range.first; } results[i] = *range.first.record; return results; this put each record inside the vector. Bjarne Stroustrup. The C++ Programming Language. \u00a710.2.1 \u21a9 https://cstack.github.io/db_tutorial/parts/part1.html \u21a9","title":"Back to the Statement class"}]}